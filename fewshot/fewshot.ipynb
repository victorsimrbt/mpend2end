{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C44s0nv1pQdl",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6Twz5IWZpQdm",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Miniconda3\\envs\\neurips\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\ProgramData\\Miniconda3\\envs\\neurips\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Flatten(start_dim=1, end_dim=-1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class prototype(nn.Module):\n",
        "    def __init__(self, backbone: nn.Module):\n",
        "        super(prototype, self).__init__()\n",
        "        self.backbone = backbone\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        support_images: torch.Tensor,\n",
        "        support_labels: torch.Tensor,\n",
        "        query_images: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Predict query labels using labeled support images.\n",
        "        \"\"\"\n",
        "        z_support = self.backbone.forward(support_images)\n",
        "        z_query = self.backbone.forward(query_images)\n",
        "\n",
        "        n_way = len(torch.unique(support_labels))\n",
        "        z_proto = torch.cat(\n",
        "            [\n",
        "                z_support[torch.nonzero(support_labels == label)].mean(0)\n",
        "                for label in range(n_way)\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        dists = torch.cdist(z_query, z_proto)\n",
        "        scores = -dists\n",
        "        return scores\n",
        "\n",
        "\n",
        "convolutional_network = resnet18(pretrained=True)\n",
        "convolutional_network.fc = nn.Flatten()\n",
        "print(convolutional_network)\n",
        "\n",
        "model = prototype(convolutional_network).cuda()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ground Truth / Predicted\n",
            "0.918918918918919\n"
          ]
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "\n",
        "image_size = 256\n",
        "\n",
        "def get_img(path):\n",
        "    image = Image.open(path)\n",
        "    totensor = transforms.ToTensor()\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "            # Omniglot images have 1 channel, but our model will expect 3-channel images\n",
        "            transforms.Resize([int(image_size * 1.15), int(image_size * 1.15)]),\n",
        "            transforms.CenterCrop(image_size),\n",
        "        ]\n",
        "    )\n",
        "    transformed = transform(image)\n",
        "    # transformed.show()\n",
        "    return totensor(transformed)[:3]\n",
        "\n",
        "def get_imgs(path):\n",
        "    tensor = []\n",
        "    imgs = os.listdir(path)\n",
        "    for img in imgs:\n",
        "        img_path = os.path.join(path,img)\n",
        "        tensor.append(get_img(img_path))\n",
        "    return torch.stack(tensor)\n",
        "\n",
        "def train_test(tensor,split=0.8):\n",
        "    idx = int(tensor.shape[0] * split)\n",
        "    return tensor[:idx],tensor[idx:]\n",
        "\n",
        "def construct(lsts):\n",
        "    imgs = torch.concatenate(lsts)\n",
        "    labels = []\n",
        "    cnt = 0 \n",
        "    for val in lsts:\n",
        "        labels += [cnt for i in range(len(val))]\n",
        "        cnt += 1\n",
        "    labels = torch.Tensor(labels)\n",
        "    return imgs,labels\n",
        "    \n",
        "\n",
        "\n",
        "BASE = r\"C:\\Users\\victo\\Desktop\\Files\\Tech\\Code\\Python\\neurips\\fewshot\\mpdata\"\n",
        "bead = get_imgs(os.path.join(BASE,\"Bead\")).cuda()\n",
        "fiber = get_imgs(os.path.join(BASE,\"Fiber\")).cuda()\n",
        "fragment = get_imgs(os.path.join(BASE,\"Fragment\")).cuda()\n",
        "negative = get_imgs(r\"C:\\Users\\victo\\Desktop\\Files\\Tech\\Code\\Python\\neurips\\negative\").cuda()\n",
        "\n",
        "bead_train,bead_test = train_test(bead)\n",
        "fiber_train,fiber_test = train_test(fiber)\n",
        "fragment_train,fragment_test = train_test(fragment)\n",
        "negative_train,negative_test = train_test(negative)\n",
        "\n",
        "labels = []\n",
        "\n",
        "test_images,test_labels = construct([negative_test,bead_test,fiber_test,fragment_test])\n",
        "train_images,train_labels = construct([negative_train,bead_train,fiber_train,fragment_train])\n",
        "\n",
        "scores = model(\n",
        "    train_images.cuda(),\n",
        "    train_labels.cuda(),\n",
        "    test_images.cuda()\n",
        ")\n",
        "\n",
        "_, pred_labels = torch.max(scores.data, 1)\n",
        "\n",
        "print(\"Ground Truth / Predicted\")\n",
        "total = 0\n",
        "for i in range(len(pred_labels)):\n",
        "    if pred_labels[i] == test_labels[i]:\n",
        "        total += 1\n",
        "    # print(pred_labels[i],test_labels[i]\n",
        "print(total/len(pred_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "negative = get_imgs(r\"C:\\Users\\victo\\Desktop\\Files\\Tech\\Code\\Python\\neurips\\negative\").cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "example_scores = model(\n",
        "    example_support_images.cuda(),\n",
        "    example_support_labels.cuda(),\n",
        "    example_query_images.cuda(),\n",
        ").detach()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "my_first_few_shot_classifier.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
