{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import blur_detector\n",
    "from matplotlib import pyplot as plt\n",
    "# Open a connection to the default camera (usually the webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "blurs = []\n",
    "\n",
    "# Check if the camera opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video stream or file\")\n",
    "    exit()\n",
    "    \n",
    "def composite(im1,im2):\n",
    "    # ! im2 is the depthmap\n",
    "    background,foreground = im1,im2\n",
    "    alpha_background = background[:,:,3] / 255.0\n",
    "    alpha_foreground = foreground[:,:,3] / 255.0\n",
    "\n",
    "    for color in range(0, 3):\n",
    "        background[:,:,color] = alpha_foreground * foreground[:,:,color] + \\\n",
    "            alpha_background * background[:,:,color] * (1 - alpha_foreground)\n",
    "\n",
    "    background[:,:,3] = (1 - (1 - alpha_foreground) * (1 - alpha_background)) * 255\n",
    "\n",
    "    cv2.imshow(\"Composited image\", background)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "# Read and display frames in a loop\n",
    "cnt = 0\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If frame reading was not successful, break the loop\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture image\")\n",
    "        break\n",
    "\n",
    "    # Display the resulting frame\n",
    "    flipped = cv2.flip(frame, 0)\n",
    "    flipped = cv2.flip(flipped, 1)\n",
    "    cv2.imshow('Camera Output', flipped)\n",
    "\n",
    "    # Press 'q' to exit the video display\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "        cv2.imwrite(os.path.join(r\"REDACTED\",'image{}.jpg'.format(cnt)), flipped)\n",
    "        cnt += 1\n",
    "        # break\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('b'):\n",
    "        print(flipped.shape)\n",
    "        gray = cv2.cvtColor(flipped, cv2.COLOR_BGR2GRAY)\n",
    "        blur_map = blur_detector.detectBlur(gray, downsampling_factor=4, num_scales=4, scale_start=2, num_iterations_RF_filter=3, show_progress=True)\n",
    "        blurs.append(blur_map)\n",
    "        # image = cv2.cvtColor(flipped, cv2.COLOR_BGR2RGB)\n",
    "        image = flipped\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(image)\n",
    "        ax.imshow(blur_map, alpha=0.5)\n",
    "        ax.axis('off')\n",
    "\n",
    "        # output_path = os.path.join(r\"C:\\Users\\victo\\Desktop\\Files\\Tech\\Code\\Python\\neurips\\captures\",'image{}.jpg'.format(cnt))\n",
    "        cv2.imwrite(os.path.join(r\"REDACTED\",'image{}.jpg'.format(cnt)), flipped)\n",
    "        plt.show()\n",
    "        cnt += 1\n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import blur_detector\n",
    "from matplotlib import pyplot as plt\n",
    "imgs = [img for img in os.listdir(r\"REDACTED\")][1:]\n",
    "cnt = 0\n",
    "blurs = []\n",
    "images = []\n",
    "for img in imgs:\n",
    "    path = os.path.join(r\"REDACTED\",img)\n",
    "    image = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "    images.append(image)\n",
    "    print(image.shape)\n",
    "    print(\"image\",cnt)\n",
    "    blur_map = blur_detector.detectBlur(image, downsampling_factor=1, show_progress = False, num_scales=4, scale_start=2, num_iterations_RF_filter=3)\n",
    "    blurs.append(blur_map)\n",
    "    plt.imshow(image,cmap=\"grey\")\n",
    "    plt.imshow(blurs[cnt],alpha = 0.6)\n",
    "    cnt += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def align_images_sift(img1, img2, idx):\n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    # Find keypoints and descriptors using SIFT\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    # Use FLANN matcher\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # Ratio test to find good matches\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    # Minimum number of matches to find homography\n",
    "    MIN_MATCH_COUNT = 10\n",
    "    if len(good_matches) >= MIN_MATCH_COUNT:\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        # Find homography matrix and mask\n",
    "        H, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        aligned_img = cv2.warpPerspective(img1, H, (img2.shape[1], img2.shape[0]))\n",
    "        aligned_img = cv2.warpPerspective(blurs[idx], H, (img2.shape[1], img2.shape[0]))\n",
    "\n",
    "        return aligned_img, H\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Not enough matches are found - %d/%d\" % (len(good_matches), MIN_MATCH_COUNT))\n",
    "\n",
    "base = image[0]\n",
    "contour = np.zeros((480,640))\n",
    "depths = [0,0,0.13,0.01,0.01,0.1,0.07,0,0,0,0.07,0.03,0.01,0.02]\n",
    "depths = np.array(depths)*1.2\n",
    "for i in range(len(images)):\n",
    "    if i == 2 or i == len(images)-1:\n",
    "        continue\n",
    "    try:\n",
    "        aligned_img, H = align_images_sift(images[i],images[0],i)\n",
    "    except:\n",
    "        pass\n",
    "    # print(aligned_img.shape)\n",
    "    print(depths[i],aligned_img)\n",
    "    # contour = np.maximum(aligned_img*depths[i],contour)\n",
    "    min_val = np.min(aligned_img)\n",
    "    max_val = np.max(aligned_img)\n",
    "\n",
    "    # Step 2: Normalize to range [0, 0.05]\n",
    "    aligned_img = 0.05 * (aligned_img - min_val) / (max_val - min_val)\n",
    "    contour = np.maximum(contour,depths[i]*(aligned_img>0.01)+aligned_img*3*(aligned_img>0.01))\n",
    "    # contour += np.maximum(contour,depths[i]+aligned_img/100)\n",
    "    # plt.colorbar()\n",
    "    plt.imshow(depths[i]+aligned_img/10)\n",
    "    print(np.max(depths[i]+aligned_img/10))\n",
    "    plt.show()\n",
    "# ! the first image is the one being aligned with\n",
    "# plt.imshow(images[1])\n",
    "# plt.imshow(aligned_img,alpha = 0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_contour(contour):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    zs = []\n",
    "    cs = []\n",
    "    thresh = 0.01\n",
    "    for i in range(contour.shape[0]):\n",
    "        for j in range(contour.shape[1]):\n",
    "            if contour[i][j] > thresh and images[0][i][j] < 100:\n",
    "                xs.append(i)\n",
    "                ys.append(j)\n",
    "                zs.append(contour[i][j])\n",
    "                # print(image[0][i][j])\n",
    "                cs.append(images[0][i][j])\n",
    "    plt.imshow(contour)\n",
    "    return cs,xs,ys,zs\n",
    "\n",
    "cs,xs,ys,zs = extract_contour(contour)\n",
    "print(len(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "# Generate random 3D points\n",
    "\n",
    "# xs = np.random.randn(100)\n",
    "# ys = np.random.randn(100)\n",
    "# zs = np.random.randn(100)\n",
    "\n",
    "np.random.seed(0)\n",
    "n_points = 100\n",
    "\n",
    "# Create a trace\n",
    "trace = go.Scatter3d(\n",
    "    x=xs,\n",
    "    y=ys,\n",
    "    z=zs,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,    \n",
    "        color = zs,# set color to an array/list of desired values\n",
    "        opacity=0.4\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create layout\n",
    "layout = go.Layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(title='X Axis',visible=False),\n",
    "        yaxis=dict(title='Y Axis',visible=False),\n",
    "        zaxis=dict(range = [0,2],title='Z Axis',visible=False),\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=0)\n",
    ")\n",
    "\n",
    "# Create a figure\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "# fig.update_xaxes(visible=False)\n",
    "# fig.update_yaxes(visible=False)\n",
    "\n",
    "# Plot the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and axis\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot 3D scatter plot\n",
    "scatter = ax.scatter(xs, ys, zs)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('X Label')\n",
    "ax.set_ylabel('Y Label')\n",
    "ax.set_zlabel('Z Label')\n",
    "ax.set_title('3D Scatter Plot')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import Delaunay\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Step 1: Generate or load 3D points\n",
    "# For this example, we'll generate random 3D points\n",
    "np.random.seed(0)\n",
    "points = np.stack((np.array(xs),np.array(ys),np.array(zs)),axis = 1)\n",
    "\n",
    "# Step 2: Perform Delaunay Triangulation\n",
    "tri = Delaunay(points)\n",
    "\n",
    "# Extract the simplices (triangles/tetrahedrons)\n",
    "simplices = tri.simplices\n",
    "\n",
    "# Step 3: Visualize the mesh\n",
    "# Create a list of Mesh3d elements for Plotly\n",
    "mesh3d = go.Mesh3d(\n",
    "    x=points[:, 0],\n",
    "    y=points[:, 1],\n",
    "    z=points[:, 2],\n",
    "    i=simplices[:, 0],\n",
    "    j=simplices[:, 1],\n",
    "    k=simplices[:, 2],\n",
    "    opacity=0.01,\n",
    "    color='blue'\n",
    ")\n",
    "\n",
    "# Create a scatter plot of the points for better visualization\n",
    "\n",
    "def tetrahedron_volume(p1, p2, p3, p4):\n",
    "    return np.abs(np.dot(p1 - p4, np.cross(p2 - p4, p3 - p4))) / 6.0\n",
    "\n",
    "scatter3d = go.Scatter3d(\n",
    "    x=points[:, 0],\n",
    "    y=points[:, 1],\n",
    "    z=points[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=0.1, color='red')\n",
    ")\n",
    "\n",
    "# Create the figure and add the Mesh3d and Scatter3d\n",
    "fig = go.Figure(data=[mesh3d])\n",
    "\n",
    "# Update layout for better visualization\n",
    "fig.update_layout(scene=dict(\n",
    "                    xaxis=dict(visible=False),  # Range for x-axis\n",
    "                    yaxis=dict(visible=False),  # Range for y-axis\n",
    "                    zaxis=dict(range=[0, 1],visible=False)  # Range for z-axis\n",
    "                ))\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.stack((np.array(xs),np.array(ys),np.array(zs)),axis = 1)\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_map_normalized = cv2.normalize(blur_map, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "blur_map_colored = cv2.applyColorMap(blur_map_normalized, cv2.COLORMAP_JET)\n",
    "\n",
    "        # Blend the original image and the colored depth map\n",
    "blended_image = cv2.addWeighted(flipped, 0.6, blur_map_colored, 0.4, 0)\n",
    "plt.imshow(blended_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_map_colored.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def variance_of_laplacian(image):\n",
    "    return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "\n",
    "def get_blur(image):\n",
    "    kernel_size = 3\n",
    "\n",
    "# def get_blurriness(image):\n",
    "    \n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(r'C:\\Users\\victo\\Desktop\\Files\\Tech\\Code\\Python\\neurips\\captures\\image0.jpg')\n",
    "print(image.shape)\n",
    "# cv2.imshow('Most Blurry Section', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import blur_detector\n",
    "\n",
    "image = cv2.imread(r'C:\\Users\\victo\\Desktop\\Files\\Tech\\Code\\Python\\neurips\\captures\\image0.jpg',0)\n",
    "blur_map = blur_detector.detectBlur(image, downsampling_factor=1, num_scales=4, scale_start=2, num_iterations_RF_filter=3, show_progress=True)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)\n",
    "plt.imshow(blur_map,alpha=0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurips",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
