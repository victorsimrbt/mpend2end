{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "image_size = 256\n",
    "\n",
    "def get_img(path):\n",
    "    image = Image.open(path)\n",
    "    totensor = transforms.ToTensor()\n",
    "    transform=transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize([int(image_size * 1.15), int(image_size * 1.15)]),\n",
    "            transforms.CenterCrop(image_size),\n",
    "        ]\n",
    "    )\n",
    "    transformed = transform(image)\n",
    "    return totensor(transformed)[:3]\n",
    "\n",
    "\n",
    "def get_imgs(path):\n",
    "    tensor = []\n",
    "    imgs = os.listdir(path)\n",
    "    for img in imgs:\n",
    "        img_path = os.path.join(path,img)\n",
    "        tensor.append(get_img(img_path))\n",
    "    return torch.stack(tensor)\n",
    "\n",
    "def train_test(tensor,split=0.8):\n",
    "    idx = int(tensor.shape[0] * split)\n",
    "    return tensor[:idx],tensor[idx:]\n",
    "\n",
    "def construct(lsts):\n",
    "    imgs = torch.concatenate(lsts)\n",
    "    labels = []\n",
    "    cnt = 0 \n",
    "    for val in lsts:\n",
    "        labels += [cnt for i in range(len(val))]\n",
    "        cnt += 1\n",
    "    labels = torch.Tensor(labels)\n",
    "    return imgs,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from main import segment\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "BASE = \"REDACTED\"\n",
    "imgs = [os.path.join(BASE,img) for img in os.listdir(BASE)]\n",
    "\n",
    "\n",
    "save = \"REDACTED\"\n",
    "\n",
    "cnt = 0\n",
    "for i in range(len(imgs)):\n",
    "    image = imageio.imread(os.path.join(BASE,imgs[i]))\n",
    "    height, width = image.shape[:2]\n",
    "    w = width//4\n",
    "    h = height//4\n",
    "    img = cv2.resize(image, (w,h))\n",
    "    output,u = segment(img,0.5,300,100)\n",
    "\n",
    "    vals = {}\n",
    "    # ! vals[x] = [min_x,max_x,min_y,max_y]\n",
    "\n",
    "    for y in range(h):\n",
    "        for x in range(w):\n",
    "            obj = u.find(y * w + x)\n",
    "            if obj in vals:\n",
    "                min_x,max_x,min_y,max_y = vals[obj]\n",
    "                vals[obj] = [min(x,min_x),max(x,max_x),min(y,min_y),max(y,max_y)]\n",
    "            else:\n",
    "                vals[obj] = [x,y,x,y]\n",
    "\n",
    "    cnt += 1\n",
    "    file_name = \"image_{}.jpg\".format(cnt)\n",
    "    for obj in vals:\n",
    "        min_x,max_x,min_y,max_y = vals[obj]\n",
    "        if max_x-min_x > 50 and max_y-min_y > 50:\n",
    "            obj_img = img[min_y:max_y+1, min_x:max_x+1]\n",
    "            imageio.imwrite(os.path.join(save,file_name), obj_img)\n",
    "        else:\n",
    "            print(\"no\")\n",
    "            # plt.imshow(obj_img)\n",
    "            # plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.imwrite(os.path.join(save,file_name), obj_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurips",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
